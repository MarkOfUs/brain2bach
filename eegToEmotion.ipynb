{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, pathlib, re\n",
        "\n",
        "def sh(cmd):\n",
        "    print(\">>\", cmd)\n",
        "    subprocess.check_call(cmd, shell=True)\n",
        "\n",
        "sh(f\"{sys.executable} -m pip -q install --upgrade pip setuptools wheel\")\n",
        "sh(f\"{sys.executable} -m pip -q install synapseclient scikit-learn matplotlib tqdm\")\n",
        "sh(f\"{sys.executable} -m pip -q install mne mne-connectivity xmltodict numpy scipy pandas joblib\")\n",
        "sh(f\"{sys.executable} -m pip -q uninstall -y torcheeg || true\")\n",
        "sh(\"rm -rf torcheeg_src\")\n",
        "sh(\"git clone --depth 1 --branch v1.1.3 https://github.com/torcheeg/torcheeg.git torcheeg_src\")\n",
        "\n",
        "setup_py = pathlib.Path(\"torcheeg_src/setup.py\")\n",
        "txt = setup_py.read_text()\n",
        "\n",
        "# Remove scipy<=1.10.1 constraint\n",
        "txt2 = re.sub(r\"scipy>=1\\.7\\.3\\s*,\\s*<=\\s*1\\.10\\.1\", \"scipy>=1.7.3\", txt)\n",
        "setup_py.write_text(txt2)\n",
        "\n",
        "# now install with deps\n",
        "sh(f\"{sys.executable} -m pip -q install ./torcheeg_src\")"
      ],
      "metadata": {
        "id": "Tc7Chg7It8w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "SEED = 0\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)\n",
        "\n",
        "ROOT = Path(\"./FACED_torcheeg\")\n",
        "DL   = ROOT/\"downloads\"\n",
        "DATA = ROOT/\"data\"\n",
        "DL.mkdir(parents=True, exist_ok=True)\n",
        "DATA.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EMO = [\"anger\",\"disgust\",\"fear\",\"sadness\",\"neutral\",\"amusement\",\"inspiration\",\"joy\",\"tenderness\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS58CkthuiiM",
        "outputId": "c8797567-7ac5-49c0-e260-f0a79f1c1a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, getpass, synapseclient, os\n",
        "\n",
        "SYN_EEG_FEATURES = \"syn52368847\"\n",
        "\n",
        "token = os.environ.get(\"SYNAPSE_AUTH_TOKEN\")\n",
        "if not token:\n",
        "    token = getpass.getpass(\"Synapse Personal Access Token: \").strip()\n",
        "\n",
        "syn = synapseclient.Synapse()\n",
        "syn.login(authToken=token, silent=True)\n",
        "\n",
        "ent = syn.get(SYN_EEG_FEATURES, downloadLocation=str(DL))\n",
        "feat_zip = Path(ent.path)\n",
        "print(\"Downloaded:\", feat_zip)\n",
        "\n",
        "feat_dir = DATA/\"EEG_Features_unzipped\"\n",
        "feat_dir.mkdir(parents=True, exist_ok=True)\n",
        "marker = feat_dir/\".unzipped_ok\"\n",
        "\n",
        "if not marker.exists():\n",
        "    with zipfile.ZipFile(feat_zip, \"r\") as z:\n",
        "        z.extractall(feat_dir)\n",
        "    marker.write_text(\"ok\")\n",
        "\n",
        "cands = [\n",
        "    feat_dir/\"EEG_Features\"/\"DE\",\n",
        "    feat_dir/\"DE\",\n",
        "]\n",
        "DE_path = next((p for p in cands if p.exists()), None)\n",
        "print(\"DE_path:\", DE_path)\n",
        "assert DE_path is not None, \"Couldn't find EEG_Features/DE after unzip.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMm_QOiluj0X",
        "outputId": "029d5275-3a41-4654-92ea-1b8a56a679e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synapse Personal Access Token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[WARNING] /tmp/ipython-input-3059162937.py:13: DeprecationWarning: Call to deprecated method get. (To be removed in 5.0.0. Use `from synapseclient.operations import get` instead.) -- Deprecated since version 4.11.0.\n",
            "  ent = syn.get(SYN_EEG_FEATURES, downloadLocation=str(DL))\n",
            "\n",
            "WARNING:py.warnings:/tmp/ipython-input-3059162937.py:13: DeprecationWarning: Call to deprecated method get. (To be removed in 5.0.0. Use `from synapseclient.operations import get` instead.) -- Deprecated since version 4.11.0.\n",
            "  ent = syn.get(SYN_EEG_FEATURES, downloadLocation=str(DL))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[syn52368847:EEG_Features.zip]: Found existing file at /content/FACED_torcheeg/downloads/EEG_Features.zip, skipping download.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:synapseclient_default:[syn52368847:EEG_Features.zip]: Found existing file at /content/FACED_torcheeg/downloads/EEG_Features.zip, skipping download.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: /content/FACED_torcheeg/downloads/EEG_Features.zip\n",
            "DE_path: FACED_torcheeg/data/EEG_Features_unzipped/EEG_Features/DE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheeg.datasets import FACEDFeatureDataset\n",
        "from torcheeg import transforms\n",
        "from torcheeg.datasets.constants import FACED_CHANNEL_LOCATION_DICT\n",
        "\n",
        "IO_PATH = str((DATA/\"io_faced_de\").resolve())\n",
        "\n",
        "dataset = FACEDFeatureDataset(\n",
        "    root_path=str(DE_path),\n",
        "    offline_transform=transforms.ToGrid(FACED_CHANNEL_LOCATION_DICT),\n",
        "    online_transform=transforms.ToTensor(),\n",
        "    label_transform=transforms.Select(\"emotion\"),\n",
        "    io_mode=\"pickle\",\n",
        "    io_path=IO_PATH,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"len(dataset) =\", len(dataset))\n",
        "\n",
        "item = dataset[0]\n",
        "print(\"len(dataset[0]) =\", len(item))\n",
        "print(\"type(dataset[0][0]) =\", type(item[0]), \"shape =\", tuple(item[0].shape))\n",
        "print(\"label =\", int(item[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhNeLv0fuls_",
        "outputId": "484d0879-df61-4e68-b7ec-22e391545001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2026-02-15 10:26:59] INFO (torcheeg/MainThread) üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m/content/FACED_torcheeg/data/io_faced_de\u001b[0m.\n",
            "INFO:torcheeg:üîç | Processing EEG data. Processed EEG data has been cached to \u001b[92m/content/FACED_torcheeg/data/io_faced_de\u001b[0m.\n",
            "[2026-02-15 10:26:59] INFO (torcheeg/MainThread) ‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
            "INFO:torcheeg:‚è≥ | Monitoring the detailed processing of a record for debugging. The processing of other records will only be reported in percentage to keep it clean.\n",
            "[PROCESS]:   0%|          | 0/123 [00:00<?, ?it/s]\n",
            "[RECORD FACED_torcheeg/data/EEG_Features_unzipped/EEG_Features/DE/sub000.pkl]: 0it [00:00, ?it/s]\u001b[A\n",
            "[RECORD FACED_torcheeg/data/EEG_Features_unzipped/EEG_Features/DE/sub000.pkl]: 657it [00:00, 6561.43it/s]\u001b[A\n",
            "[PROCESS]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:15<00:00,  7.99it/s]\n",
            "[2026-02-15 10:27:14] INFO (torcheeg/MainThread) ‚úÖ | All processed EEG data has been cached to /content/FACED_torcheeg/data/io_faced_de.\n",
            "INFO:torcheeg:‚úÖ | All processed EEG data has been cached to /content/FACED_torcheeg/data/io_faced_de.\n",
            "[2026-02-15 10:27:14] INFO (torcheeg/MainThread) üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m/content/FACED_torcheeg/data/io_faced_de\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n",
            "INFO:torcheeg:üòä | Please set \u001b[92mio_path\u001b[0m to \u001b[92m/content/FACED_torcheeg/data/io_faced_de\u001b[0m for the next run, to directly read from the cache if you wish to skip the data processing step.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(dataset) = 103320\n",
            "len(dataset[0]) = 2\n",
            "type(dataset[0][0]) = <class 'torch.Tensor'> shape = (5, 8, 9)\n",
            "label = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "N = len(dataset)\n",
        "\n",
        "try:\n",
        "    labels = np.fromiter((int(dataset.read_info(i)[\"emotion\"]) for i in range(N)),\n",
        "                         dtype=np.int64, count=N)\n",
        "except Exception as e:\n",
        "    print(\"read_info failed, falling back to dataset[i][1] labels:\", e)\n",
        "    labels = np.fromiter((int(dataset[i][1]) for i in range(N)),\n",
        "                         dtype=np.int64, count=N)\n",
        "\n",
        "idx = np.arange(N)\n",
        "\n",
        "idx_train, idx_tmp, y_train, y_tmp = train_test_split(\n",
        "    idx, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
        ")\n",
        "idx_val, idx_test, y_val, y_test = train_test_split(\n",
        "    idx_tmp, y_tmp, test_size=0.5, random_state=SEED, stratify=y_tmp\n",
        ")\n",
        "\n",
        "print(\"splits:\", len(idx_train), len(idx_val), len(idx_test))\n",
        "print(\"train class counts:\", np.bincount(y_train, minlength=9))\n",
        "\n",
        "class Wrap(Dataset):\n",
        "    def __init__(self, base, indices):\n",
        "        self.base = base\n",
        "        self.indices = np.asarray(indices)\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    def __getitem__(self, i):\n",
        "        x, y = self.base[int(self.indices[i])]\n",
        "        x = x.float()\n",
        "        # per-sample normalization\n",
        "        mu = x.mean(dim=(1,2), keepdim=True)\n",
        "        sd = x.std(dim=(1,2), keepdim=True).clamp_min(1e-6)\n",
        "        x = (x - mu) / sd\n",
        "        return x, int(y)\n",
        "\n",
        "train_loader = DataLoader(Wrap(dataset, idx_train), batch_size=256, shuffle=True,  num_workers=0)\n",
        "val_loader   = DataLoader(Wrap(dataset, idx_val),   batch_size=512, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(Wrap(dataset, idx_test),  batch_size=512, shuffle=False, num_workers=0)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"batch:\", xb.shape, yb.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5FQ-QxnunNB",
        "outputId": "80e2d617-3d60-401d-99d7-ef6cddbe3838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "splits: 82656 10332 10332\n",
            "train class counts: [ 8856  8856  8856  8856 11808  8856  8856  8856  8856]\n",
            "batch: torch.Size([256, 5, 8, 9]) torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "in_ch = xb.shape[1]\n",
        "H, W  = xb.shape[-2], xb.shape[-1]\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = SmallCNN(in_channels=in_ch, num_classes=9).to(device)\n",
        "\n",
        "counts = np.bincount(y_train, minlength=9).astype(np.float32)\n",
        "weights = (counts.sum() / (counts + 1e-6))\n",
        "weights = weights / weights.mean()\n",
        "class_w = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
        "\n",
        "print(\"model ok | in_ch:\", in_ch, \"| grid:\", (H, W))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSU-mUlkuqyu",
        "outputId": "79ea701c-643f-4571-97d3-d5740e147055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ok | in_ch: 5 | grid: (8, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def run_epoch(loader, train: bool):\n",
        "    model.train(train)\n",
        "    total_loss, total_correct, total_n = 0.0, 0, 0\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += float(loss.item()) * len(yb)\n",
        "        total_correct += int((logits.argmax(1) == yb).sum().item())\n",
        "        total_n += len(yb)\n",
        "\n",
        "    return total_loss / total_n, total_correct / total_n\n",
        "\n",
        "\n",
        "MAX_EPOCHS = 200\n",
        "PATIENCE   = 12       # stop after this many epochs w/o val improvement\n",
        "MIN_DELTA  = 1e-3\n",
        "MIN_EPOCHS = 10\n",
        "\n",
        "trL, vaL, trA, vaA = [], [], [], []\n",
        "best_val_loss, best_state, best_epoch = float(\"inf\"), None, -1\n",
        "bad_epochs = 0\n",
        "\n",
        "for e in range(1, MAX_EPOCHS + 1):\n",
        "    tl, ta = run_epoch(train_loader, True)\n",
        "    vl, va = run_epoch(val_loader, False)\n",
        "\n",
        "    trL.append(tl); trA.append(ta)\n",
        "    vaL.append(vl); vaA.append(va)\n",
        "\n",
        "    improved = (vl < best_val_loss - MIN_DELTA)\n",
        "    if improved:\n",
        "        best_val_loss = vl\n",
        "        best_epoch = e\n",
        "        bad_epochs = 0\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "\n",
        "    print(f\"epoch {e:03d} | train loss {tl:.4f} acc {ta:.3f} | val loss {vl:.4f} acc {va:.3f} \"\n",
        "          f\"| best val loss {best_val_loss:.4f} @ {best_epoch:03d} | patience {bad_epochs}/{PATIENCE}\")\n",
        "\n",
        "    if e >= MIN_EPOCHS and bad_epochs >= PATIENCE:\n",
        "        print(f\"Early stopping: no val loss improvement for {PATIENCE} epochs. Stopping at epoch {e}.\")\n",
        "        break\n",
        "\n",
        "# restore best (lowest val loss)\n",
        "model.load_state_dict(best_state)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(trL, label=\"train loss\")\n",
        "plt.plot(vaL, label=\"val loss\")\n",
        "plt.axvline(best_epoch-1, linestyle=\"--\", label=\"best epoch (val loss)\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss curves\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(trA, label=\"train acc\")\n",
        "plt.plot(vaA, label=\"val acc\")\n",
        "plt.axvline(best_epoch-1, linestyle=\"--\", label=\"best epoch (val loss)\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy curves\")\n",
        "plt.show()\n",
        "\n",
        "print(\"best val loss:\", best_val_loss, \"at epoch\", best_epoch)\n",
        "print(\"val acc at best loss epoch:\", vaA[best_epoch-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "9MATh1tgus0X",
        "outputId": "3b2508dc-7def-4fd4-c55d-b59a21d10c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 001 | train loss 2.1911 acc 0.126 | val loss 2.1738 acc 0.160 | best val loss 2.1738 @ 001 | patience 0/12\n",
            "epoch 002 | train loss 2.1639 acc 0.161 | val loss 2.1612 acc 0.167 | best val loss 2.1612 @ 002 | patience 0/12\n",
            "epoch 003 | train loss 2.1479 acc 0.175 | val loss 2.1755 acc 0.159 | best val loss 2.1612 @ 002 | patience 1/12\n",
            "epoch 004 | train loss 2.1341 acc 0.185 | val loss 2.1267 acc 0.191 | best val loss 2.1267 @ 004 | patience 0/12\n",
            "epoch 005 | train loss 2.1166 acc 0.195 | val loss 2.1113 acc 0.204 | best val loss 2.1113 @ 005 | patience 0/12\n",
            "epoch 006 | train loss 2.0944 acc 0.205 | val loss 2.1011 acc 0.206 | best val loss 2.1011 @ 006 | patience 0/12\n",
            "epoch 007 | train loss 2.0642 acc 0.220 | val loss 2.0784 acc 0.218 | best val loss 2.0784 @ 007 | patience 0/12\n",
            "epoch 008 | train loss 2.0264 acc 0.238 | val loss 2.0736 acc 0.228 | best val loss 2.0736 @ 008 | patience 0/12\n",
            "epoch 009 | train loss 1.9810 acc 0.258 | val loss 2.0156 acc 0.253 | best val loss 2.0156 @ 009 | patience 0/12\n",
            "epoch 010 | train loss 1.9349 acc 0.276 | val loss 1.9450 acc 0.274 | best val loss 1.9450 @ 010 | patience 0/12\n",
            "epoch 011 | train loss 1.8873 acc 0.293 | val loss 1.9361 acc 0.273 | best val loss 1.9361 @ 011 | patience 0/12\n",
            "epoch 012 | train loss 1.8416 acc 0.310 | val loss 1.8855 acc 0.292 | best val loss 1.8855 @ 012 | patience 0/12\n",
            "epoch 013 | train loss 1.7967 acc 0.322 | val loss 1.9242 acc 0.284 | best val loss 1.8855 @ 012 | patience 1/12\n",
            "epoch 014 | train loss 1.7590 acc 0.338 | val loss 1.8808 acc 0.296 | best val loss 1.8808 @ 014 | patience 0/12\n",
            "epoch 015 | train loss 1.7229 acc 0.349 | val loss 1.8642 acc 0.310 | best val loss 1.8642 @ 015 | patience 0/12\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1956863387.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mvl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1956863387.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3011510682.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# per-sample normalization (cheap + helps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torcheeg/datasets/module/emotion_recognition/faced_feature.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0meeg_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clip_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torcheeg/datasets/module/base_dataset.py\u001b[0m in \u001b[0;36mread_info\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         '''\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1205\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4303\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4305\u001b[0;31m             \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleaved_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "preds, trues = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        logits = model(xb)\n",
        "        preds.append(logits.argmax(1).cpu().numpy())\n",
        "        trues.append(np.asarray(yb))\n",
        "\n",
        "y_pred = np.concatenate(preds)\n",
        "y_true = np.concatenate(trues)\n",
        "\n",
        "print(\"Test acc:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, target_names=EMO, digits=3, zero_division=0))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=np.arange(9))\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(cm)\n",
        "plt.title(\"Confusion matrix (test)\")\n",
        "plt.xlabel(\"pred\"); plt.ylabel(\"true\")\n",
        "plt.xticks(range(9), EMO, rotation=45, ha=\"right\")\n",
        "plt.yticks(range(9), EMO)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdDryJbbvCSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, time, hashlib\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "if \"best_state\" in globals() and best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "meta = {\n",
        "    \"saved_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "    \"task\": \"EEG emotion classification (FACED DE -> 2D scalp grid -> CNN)\",\n",
        "    \"classes\": EMO if \"EMO\" in globals() else None,\n",
        "    \"num_classes\": len(EMO) if \"EMO\" in globals() else None,\n",
        "    \"input_tensor_shape\": [1, 5, 8, 9],   # (B, BANDS, H, W) for inference\n",
        "    \"bands\": 5,\n",
        "    \"grid_hw\": [8, 9],\n",
        "    \"notes\": \"Checkpoint contains model.state_dict only; recreate architecture in inference code before loading.\"\n",
        "}\n",
        "\n",
        "out_dir = Path(\"export_ckpt\")\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "ckpt_path = out_dir / \"cnn_faced_best.pt\"\n",
        "meta_path = out_dir / \"cnn_faced_best.meta.json\"\n",
        "\n",
        "torch.save(\n",
        "    {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"meta\": meta,\n",
        "    },\n",
        "    ckpt_path\n",
        ")\n",
        "\n",
        "meta_path.write_text(json.dumps(meta, indent=2))\n",
        "\n",
        "sha256 = hashlib.sha256(ckpt_path.read_bytes()).hexdigest()\n",
        "(out_dir / \"sha256.txt\").write_text(sha256 + \"\\n\")\n",
        "\n",
        "print(\"Saved checkpoint:\", ckpt_path)\n",
        "print(\"Saved metadata:\", meta_path)\n",
        "print(\"SHA256:\", sha256)\n",
        "\n",
        "import zipfile\n",
        "zip_path = Path(\"cnn_faced_export_loss_stop.zip\")\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    z.write(ckpt_path, arcname=ckpt_path.name)\n",
        "    z.write(meta_path, arcname=meta_path.name)\n",
        "    z.write(out_dir / \"sha256.txt\", arcname=\"sha256.txt\")\n",
        "\n",
        "print(\"Zipped:\", zip_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(str(zip_path))"
      ],
      "metadata": {
        "id": "u7GbNBJezv3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_uDiB5jDzXt1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}