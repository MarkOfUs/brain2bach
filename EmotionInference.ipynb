{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, pathlib, re\n",
        "\n",
        "def sh(cmd):\n",
        "    print(\">>\", cmd)\n",
        "    subprocess.check_call(cmd, shell=True)\n",
        "\n",
        "sh(f\"{sys.executable} -m pip -q install --upgrade pip setuptools wheel\")\n",
        "sh(f\"{sys.executable} -m pip -q install synapseclient scikit-learn matplotlib tqdm\")\n",
        "sh(f\"{sys.executable} -m pip -q install mne mne-connectivity xmltodict numpy scipy pandas joblib\")\n",
        "sh(f\"{sys.executable} -m pip -q uninstall -y torcheeg || true\")\n",
        "sh(\"rm -rf torcheeg_src\")\n",
        "sh(\"git clone --depth 1 --branch v1.1.3 https://github.com/torcheeg/torcheeg.git torcheeg_src\")\n",
        "\n",
        "setup_py = pathlib.Path(\"torcheeg_src/setup.py\")\n",
        "txt = setup_py.read_text()\n",
        "\n",
        "# Remove scipy<=1.10.1 constraint\n",
        "txt2 = re.sub(r\"scipy>=1\\.7\\.3\\s*,\\s*<=\\s*1\\.10\\.1\", \"scipy>=1.7.3\", txt)\n",
        "setup_py.write_text(txt2)\n",
        "\n",
        "# now install with deps\n",
        "sh(f\"{sys.executable} -m pip -q install ./torcheeg_src\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OQ-oerdB490",
        "outputId": "d163c576-44c6-40c8-de4d-ced172322fea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> /usr/bin/python3 -m pip -q install --upgrade pip setuptools wheel\n",
            ">> /usr/bin/python3 -m pip -q install synapseclient scikit-learn matplotlib tqdm\n",
            ">> /usr/bin/python3 -m pip -q install mne mne-connectivity xmltodict numpy scipy pandas joblib\n",
            ">> /usr/bin/python3 -m pip -q uninstall -y torcheeg || true\n",
            ">> rm -rf torcheeg_src\n",
            ">> git clone --depth 1 --branch v1.1.3 https://github.com/torcheeg/torcheeg.git torcheeg_src\n",
            ">> /usr/bin/python3 -m pip -q install ./torcheeg_src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTu0cDq1AAHE",
        "outputId": "5548f4b0-766b-4dbc-f1fd-144ba25ce863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fs=48.80 Hz | window=[0:250] | x=(1, 5, 8, 9)\n",
            "1. fear\t0.999450\n",
            "2. anger\t0.000550\n",
            "3. tenderness\t0.000000\n",
            "4. sadness\t0.000000\n",
            "5. inspiration\t0.000000\n",
            "6. disgust\t0.000000\n",
            "7. neutral\t0.000000\n",
            "8. joy\t0.000000\n",
            "9. amusement\t0.000000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from scipy.signal import butter, filtfilt, lfilter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torcheeg import transforms\n",
        "from torcheeg.datasets.constants import FACED_CHANNEL_LOCATION_DICT\n",
        "\n",
        "\n",
        "MAT_PATH  = \"/content/capture.mat\"\n",
        "CKPT_PATH = \"/content/cnn_faced_best.pt\"\n",
        "\n",
        "WINDOW_START = 0\n",
        "WINDOW_END   = 250\n",
        "\n",
        "FALLBACK_FS = 250.0\n",
        "\n",
        "MAT_CHANNEL_NAMES = [\"FP1\", \"FZ\", \"FP2\"]\n",
        "\n",
        "EMO_FALLBACK = [\"anger\",\"disgust\",\"fear\",\"sadness\",\"neutral\",\"amusement\",\"inspiration\",\"joy\",\"tenderness\"]\n",
        "\n",
        "BANDS = [\n",
        "    (\"delta\", 0.5, 4.0),\n",
        "    (\"theta\", 4.0, 8.0),\n",
        "    (\"alpha\", 8.0, 13.0),\n",
        "    (\"beta\",  13.0, 30.0),\n",
        "    (\"gamma\", 30.0, None),\n",
        "]\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def _safe_filter(x, b, a):\n",
        "    try:\n",
        "        return filtfilt(b, a, x, axis=-1)\n",
        "    except ValueError:\n",
        "        return lfilter(b, a, x, axis=-1)\n",
        "\n",
        "\n",
        "def butter_filter_1d(x, fs, low=None, high=None, order=4):\n",
        "    nyq = fs / 2.0\n",
        "    if nyq <= 0:\n",
        "        raise ValueError(f\"Bad fs={fs}\")\n",
        "\n",
        "    if low is not None and low >= nyq:\n",
        "        return np.zeros_like(x)\n",
        "    if high is not None and high >= nyq:\n",
        "        high = nyq - 1e-3\n",
        "        if high <= 0:\n",
        "            return np.zeros_like(x)\n",
        "\n",
        "    if low is None and high is None:\n",
        "        return x\n",
        "\n",
        "    if low is None:\n",
        "        wn = high / nyq\n",
        "        b, a = butter(order, wn, btype=\"lowpass\")\n",
        "    elif high is None:\n",
        "        wn = low / nyq\n",
        "        b, a = butter(order, wn, btype=\"highpass\")\n",
        "    else:\n",
        "        if low >= high:\n",
        "            return np.zeros_like(x)\n",
        "        wn = [low / nyq, high / nyq]\n",
        "        b, a = butter(order, wn, btype=\"bandpass\")\n",
        "\n",
        "    return _safe_filter(x, b, a)\n",
        "\n",
        "\n",
        "def compute_de_BxC(eeg_CxT, fs, eps=1e-8):\n",
        "    C, _ = eeg_CxT.shape\n",
        "    F = np.zeros((len(BANDS), C), dtype=np.float32)\n",
        "\n",
        "    for bi, (_, lo, hi) in enumerate(BANDS):\n",
        "        for ci in range(C):\n",
        "            x = eeg_CxT[ci].astype(np.float64)\n",
        "            xf = butter_filter_1d(x, fs, low=lo, high=hi, order=4)\n",
        "            var = np.var(xf) + eps\n",
        "            de = 0.5 * np.log(2.0 * np.pi * np.e * var)\n",
        "            F[bi, ci] = np.float32(de)\n",
        "\n",
        "    return F\n",
        "\n",
        "\n",
        "def load_eeg_from_mat(mat_path, fallback_fs=250.0):\n",
        "    mat = sio.loadmat(mat_path)\n",
        "\n",
        "    fs = None\n",
        "    if \"meta\" in mat:\n",
        "        try:\n",
        "            meta = mat[\"meta\"][0, 0]\n",
        "            if \"achieved_hz\" in meta.dtype.names:\n",
        "                fs = float(meta[\"achieved_hz\"].item())\n",
        "            elif \"target_hz\" in meta.dtype.names:\n",
        "                fs = float(meta[\"target_hz\"].item())\n",
        "        except Exception:\n",
        "            fs = None\n",
        "    if fs is None:\n",
        "        fs = float(fallback_fs)\n",
        "\n",
        "    if \"data\" in mat and isinstance(mat[\"data\"], np.ndarray) and mat[\"data\"].ndim == 2:\n",
        "        arr = mat[\"data\"]\n",
        "        if arr.shape[1] >= 2:\n",
        "            eeg_TxC = arr[:, 1:]\n",
        "            return eeg_TxC.T.astype(np.float64), fs\n",
        "\n",
        "    for key in [\"eeg\", \"EEG\", \"X\", \"signals\", \"data_eeg\"]:\n",
        "        if key in mat and isinstance(mat[key], np.ndarray):\n",
        "            x = np.squeeze(mat[key])\n",
        "            if x.ndim == 2:\n",
        "                if x.shape[0] <= x.shape[1]:\n",
        "                    return x.astype(np.float64), fs\n",
        "                else:\n",
        "                    return x.T.astype(np.float64), fs\n",
        "\n",
        "    raise KeyError(f\"Couldn't find EEG array in {mat_path}. Keys: {list(mat.keys())}\")\n",
        "\n",
        "\n",
        "def faced_channel_order():\n",
        "    return list(FACED_CHANNEL_LOCATION_DICT.keys())\n",
        "\n",
        "\n",
        "def build_full_faced_feature(F_BxC_small, mat_channel_names):\n",
        "    faced_ch = faced_channel_order()\n",
        "    F_full = np.zeros((len(BANDS), len(faced_ch)), dtype=np.float32)\n",
        "\n",
        "    name_to_idx = {name: i for i, name in enumerate(faced_ch)}\n",
        "    for j, name in enumerate(mat_channel_names):\n",
        "        if name not in name_to_idx:\n",
        "            raise ValueError(f\"Channel name '{name}' not in FACED_CHANNEL_LOCATION_DICT keys.\")\n",
        "        F_full[:, name_to_idx[name]] = F_BxC_small[:, j]\n",
        "\n",
        "    return F_full\n",
        "\n",
        "\n",
        "def togrid_like_training(F_full_BxC):\n",
        "    to_grid = transforms.ToGrid(FACED_CHANNEL_LOCATION_DICT)\n",
        "    out = to_grid(eeg=F_full_BxC.T)  # (5,30) -> (30,5)\n",
        "    return out[\"eeg\"] if isinstance(out, dict) else out\n",
        "\n",
        "\n",
        "def totensor_like_training(G_BxHxW):\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    out = to_tensor(eeg=G_BxHxW)\n",
        "    return out[\"eeg\"] if isinstance(out, dict) else out\n",
        "\n",
        "\n",
        "def normalize_like_training(x):\n",
        "    mu = x.mean(dim=(2, 3), keepdim=True)\n",
        "    sd = x.std(dim=(2, 3), keepdim=True).clamp_min(1e-6)\n",
        "    return (x - mu) / sd\n",
        "\n",
        "\n",
        "def load_model(ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "    state = ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
        "\n",
        "    classes = EMO_FALLBACK\n",
        "    if isinstance(ckpt, dict) and \"meta\" in ckpt and isinstance(ckpt[\"meta\"], dict):\n",
        "        if ckpt[\"meta\"].get(\"classes\") is not None:\n",
        "            classes = ckpt[\"meta\"][\"classes\"]\n",
        "\n",
        "    model = SmallCNN(in_channels=5, num_classes=len(classes)).to(DEVICE)\n",
        "    model.load_state_dict(state)\n",
        "    model.eval()\n",
        "    return model, classes\n",
        "\n",
        "\n",
        "def main(topk=3):\n",
        "    eeg_CxT, fs = load_eeg_from_mat(MAT_PATH, fallback_fs=FALLBACK_FS)\n",
        "\n",
        "    if eeg_CxT.shape[0] < 3:\n",
        "        raise ValueError(f\"Need at least 3 channels in mat, got {eeg_CxT.shape[0]}\")\n",
        "    eeg3 = eeg_CxT[:3, :]\n",
        "\n",
        "    eeg_win = eeg3[:, WINDOW_START:WINDOW_END]\n",
        "    if eeg_win.shape[1] < 16:\n",
        "        raise ValueError(f\"Window too short: {eeg_win.shape}\")\n",
        "\n",
        "    F_small = compute_de_BxC(eeg_win, fs)\n",
        "    F_full = build_full_faced_feature(F_small, MAT_CHANNEL_NAMES)\n",
        "    G = togrid_like_training(F_full)\n",
        "\n",
        "    t = totensor_like_training(G)\n",
        "    x = t.float().unsqueeze(0).to(DEVICE)\n",
        "    x = normalize_like_training(x)\n",
        "\n",
        "    model, classes = load_model(CKPT_PATH)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()[0]\n",
        "\n",
        "    top = probs.argsort()[-topk:][::-1]\n",
        "    print(f\"fs={fs:.2f} Hz | window=[{WINDOW_START}:{WINDOW_END}] | x={tuple(x.shape)}\")\n",
        "    for i, k in enumerate(top, 1):\n",
        "        print(f\"{i}. {classes[k]}\\t{probs[k]:.6f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(topk=9)"
      ]
    }
  ]
}